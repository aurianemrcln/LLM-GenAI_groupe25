import chainlit as cl
import os
import traceback
from chroma_client import collection, CHROMA_DIR
from litellm import completion
from rag_engine import get_similar_docs
import time 
import asyncio
# =========================
# CONFIGURATION
# =========================

os.environ["MISTRAL_API_KEY"] = "YOUR_API_KEY"

# Param√®tres RAG
SCORE_THRESHOLD = 0.65
TOP_K_DOCS = 4

# System Prompt
SYSTEM_PROMPT = """Tu es l'assistant intelligent de l'ESILV (√âcole Sup√©rieure d'Ing√©nieurs L√©onard de Vinci).

MISSION :
- Aider les √©tudiants, candidats et visiteurs √† trouver des informations sur l'√©cole
- R√©pondre pr√©cis√©ment en te basant UNIQUEMENT sur la documentation officielle fournie
- Orienter vers les bons contacts si l'information n'est pas disponible

R√àGLES STRICTES :
1. N'invente JAMAIS d'informations : si tu ne trouves pas la r√©ponse dans les documents, dis-le clairement
2. R√©ponds en fran√ßais de mani√®re claire, naturelle et professionnelle
3. Si besoin de plus d'infos, redirige vers : scolarit√©@esilv.fr
4. NE MENTIONNE PAS les sources dans ta r√©ponse (pas de "[Document X]")
5. R√©ponds comme si tu connaissais naturellement ces informations
6. Structure ta r√©ponse de mani√®re claire et accessible

STYLE DE R√âPONSE :
- Ton conversationnel et direct
- Paragraphes fluides (√©vite les listes excessives sauf si vraiment n√©cessaire)
- R√©ponse compl√®te mais concise

CONTEXTE √Ä UTILISER :
{context}

R√©ponds maintenant √† la question de l'utilisateur."""

# =========================
# INITIALISATION
# =========================

print("=" * 60)
print(" ESILV - Assistant Documentation")
print("=" * 60)
print(f" Base de donn√©es : {CHROMA_DIR}")
print(f" Documents charg√©s : {collection.count()}")
print(f" Seuil de similarit√© : {SCORE_THRESHOLD}")
print("=" * 60 + "\n")

# =========================
# HANDLERS CHAINLIT
# =========================

@cl.on_chat_start
async def start():

    await asyncio.sleep(2)
    """Message de bienvenue"""
    welcome_message = """# üëã Bienvenue sur l'assistant ESILV !

Je suis l√† pour vous aider √† trouver des informations sur :
- üìö Les formations et programmes
- üéì Les admissions et inscriptions  
- üåç L'international et les √©changes
- üíº L'alternance et les stages
- üè´ La vie √©tudiante
- üìç Les campus (Paris, Nantes, Montpellier)

**Posez-moi votre question et je rechercherai dans la documentation officielle !**

*Si je n'ai pas l'information, je vous redirigerai vers le service comp√©tent.*
"""
    await cl.Message(content=welcome_message).send()


@cl.on_message
async def on_message(message: cl.Message):
    """Traitement des questions utilisateur"""
    
    try:
        query = message.content.strip()

        if not query:
            await cl.Message(content="‚ö†Ô∏è Merci de poser une question.").send()
            return

        # Message de chargement
        loading_msg = cl.Message(content="üîç Recherche dans la documentation...")
        await loading_msg.send()

        # =========================
        # PHASE 1 : RECHERCHE RAG
        # =========================
        
        docs = await get_similar_docs(query, collection, n=TOP_K_DOCS)

        # Filtrage par score de similarit√©
        context_docs = [
            doc for doc in docs
            if doc.get("similarity", 0) >= SCORE_THRESHOLD
        ]

        # =========================
        # PHASE 2 : G√âN√âRATION DE LA R√âPONSE
        # =========================

        if context_docs:
            # Construction du contexte avec les documents pertinents
            context = "\n\n".join([
                f"[Document {i+1}]\n{doc['document']}"
                for i, doc in enumerate(context_docs)
            ])
            
            user_prompt = f"""QUESTION DE L'UTILISATEUR :
{query}

R√©ponds en te basant UNIQUEMENT sur les documents ci-dessus."""

            system_content = SYSTEM_PROMPT.format(context=context)
        
        else:
            # Aucun document pertinent trouv√©
            system_content = SYSTEM_PROMPT.format(
                context="AUCUN DOCUMENT PERTINENT TROUV√â"
            )
            user_prompt = f"""QUESTION DE L'UTILISATEUR :
{query}

Tu dois r√©pondre : "Je n'ai pas trouv√© d'informations sur ce sujet dans la documentation disponible. Pour plus de d√©tails, je vous invite √† contacter la scolarit√© √† scolarit√©@esilv.fr."
"""

        # Suppression du message de chargement
        await loading_msg.remove()

        # =========================
        # PHASE 3 : STREAMING LLM
        # =========================

        response_msg = cl.Message(content="")
        await response_msg.send()

        # Appel LLM avec streaming
        stream = completion(
            model="mistral/mistral-large-2512",
            messages=[
                {"role": "system", "content": system_content},
                {"role": "user", "content": user_prompt}
            ],
            stream=True,
            temperature=0.3  # R√©ponses plus factuelles
        )

        full_response = ""
        
        for chunk in stream:
            if chunk and "choices" in chunk:
                delta = chunk["choices"][0].get("delta", {})
                content = delta.get("content", "")
                
                if content:
                    full_response += content
                    await response_msg.stream_token(content)

        await response_msg.update()

    except Exception as e:
        traceback.print_exc()
        error_msg = f""" **Une erreur est survenue**

D√©tails : `{str(e)}`

Merci de contacter le support technique ou de r√©essayer."""
        await cl.Message(content=error_msg).send()


# =========================
# FONCTIONS UTILITAIRES
# =========================

@cl.on_chat_end
async def end():
    """Message de fin de session"""
    print(" Session termin√©e")
